{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1bWwyRpkq1LFqD52CvohEabRwwD-ZqBlN",
      "authorship_tag": "ABX9TyPeG1sAKBWJIeUKBTSBKNLC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gorovuha/text_generation/blob/main/word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "id": "xJ5YDyh6LXgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wget"
      ],
      "metadata": {
        "id": "pfm98JtQLkJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ufal.udpipe\n",
        "!pip install wget"
      ],
      "metadata": {
        "id": "_rAfpJU7ptTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wget\n",
        "import sys\n",
        "\n",
        "udpipe_url = 'https://rusvectores.org/static/models/udpipe_syntagrus.model'\n",
        "modelfile = wget.download(udpipe_url)"
      ],
      "metadata": {
        "id": "8UEA6ef4tVkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process(pipeline, text='Строка', keep_pos=True, keep_punct=False):\n",
        "   entities = {'PROPN'}\n",
        "   named = False  # переменная для запоминания того, что нам встретилось имя собственное\n",
        "   memory = []\n",
        "   mem_case = None\n",
        "   mem_number = None\n",
        "   tagged_propn = []\n",
        "\n",
        "   # обрабатываем текст, получаем результат в формате conllu:\n",
        "   processed = pipeline.process(text)\n",
        "\n",
        "   # пропускаем строки со служебной информацией:\n",
        "   content = [l for l in processed.split('\\n') if not l.startswith('#')]\n",
        "\n",
        "   # извлекаем из обработанного текста леммы, тэги и морфологические характеристики\n",
        "   tagged = [w.split('\\t') for w in content if w]\n",
        "\n",
        "   for t in tagged:\n",
        "       if len(t) != 10: # если список короткий — строчка не содержит разбора, пропускаем\n",
        "           continue\n",
        "       (word_id,token,lemma,pos,xpos,feats,head,deprel,deps,misc) = t \n",
        "       if not lemma or not token: # если слово пустое — пропускаем\n",
        "           continue\n",
        "       if pos in entities: # здесь отдельно обрабатываем имена собственные — они требуют особого обращения\n",
        "           if '|' not in feats:\n",
        "               tagged_propn.append('%s_%s' % (lemma, pos))\n",
        "               continue\n",
        "           morph = {el.split('=')[0]: el.split('=')[1] for el in feats.split('|')}\n",
        "           if 'Case' not in morph or 'Number' not in morph:\n",
        "               tagged_propn.append('%s_%s' % (lemma, pos))\n",
        "               continue\n",
        "           if not named:\n",
        "               named = True\n",
        "               mem_case = morph['Case']\n",
        "               mem_number = morph['Number']\n",
        "           if morph['Case'] == mem_case and morph['Number'] == mem_number:\n",
        "               memory.append(lemma)\n",
        "               if 'SpacesAfter=\\\\n' in misc or 'SpacesAfter=\\s\\\\n' in misc:\n",
        "                   named = False\n",
        "                   past_lemma = '::'.join(memory)\n",
        "                   memory = []\n",
        "                   tagged_propn.append(past_lemma + '_PROPN ')\n",
        "           else:\n",
        "               named = False\n",
        "               past_lemma = '::'.join(memory)\n",
        "               memory = []\n",
        "               tagged_propn.append(past_lemma + '_PROPN ')\n",
        "               tagged_propn.append('%s_%s' % (lemma, pos))\n",
        "       else:\n",
        "           if not named:\n",
        "               #if pos == 'NUM' and token.isdigit():  # Заменяем числа на xxxxx той же длины\n",
        "                #   lemma = num_replace(token)\n",
        "               tagged_propn.append('%s_%s' % (lemma, pos))\n",
        "           else:\n",
        "               named = False\n",
        "               past_lemma = '::'.join(memory)\n",
        "               memory = []\n",
        "               tagged_propn.append(past_lemma + '_PROPN ')\n",
        "               tagged_propn.append('%s_%s' % (lemma, pos))\n",
        "\n",
        "   if not keep_punct: # обрабатываем случай, когда пользователь попросил не сохранять пунктуацию (по умолчанию она сохраняется)\n",
        "       tagged_propn = [word for word in tagged_propn if word.split('_')[1] != 'PUNCT']\n",
        "   if not keep_pos:\n",
        "       tagged_propn = [word.split('_')[0] for word in tagged_propn]\n",
        "   return tagged_propn"
      ],
      "metadata": {
        "id": "2P5birSGuJEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ufal.udpipe import Model, Pipeline\n",
        "import os\n",
        "import re\n",
        "\n",
        "udpipe_model_url = 'https://rusvectores.org/static/models/udpipe_syntagrus.model'\n",
        "udpipe_filename = udpipe_model_url.split('/')[-1]\n",
        "\n",
        "if not os.path.isfile(modelfile):\n",
        "       print('UDPipe model not found. Downloading...', file=sys.stderr)\n",
        "       wget.download(udpipe_model_url)\n",
        "\n",
        "print('\\nLoading the model...', file=sys.stderr)\n",
        "model = Model.load(modelfile)\n",
        "process_pipeline = Pipeline(model, 'tokenize', Pipeline.DEFAULT, Pipeline.DEFAULT, 'conllu')\n",
        "\n",
        "def tag_ud(text='Текст нужно передать функции в виде строки!', modelfile='udpipe_syntagrus.model'):\n",
        "\n",
        "   print('Processing input...', file=sys.stderr)\n",
        "   lines = text.split('\\n')\n",
        "   tagged = []\n",
        "   for line in lines:\n",
        "       # line = unify_sym(line.strip()) # здесь могла бы быть ваша функция очистки текста\n",
        "       output = process(process_pipeline, text=line)\n",
        "       tagged_line = ' '.join(output)\n",
        "       tagged.append(tagged_line)\n",
        "   return '\\n'.join(tagged)\n",
        "\n",
        "c = 0\n",
        "for filename in os.listdir(\"/content/drive/MyDrive/kursovaya/for_modeling\"):\n",
        "  text = open(os.path.join(\"/content/drive/MyDrive/kursovaya/for_modeling\", filename), 'r', encoding='utf-8').read()\n",
        "  split_regex = re.compile(r'[.|!|?|…]')\n",
        "  sentences = filter(lambda t: t, [t.strip() for t in split_regex.split(text)])\n",
        "  sentenced_text = ''\n",
        "  for s in sentences:\n",
        "      sentenced_text += s + '\\n'\n",
        "#print(sentenced_text[0:350])\n",
        "  processed_text = tag_ud(text=sentenced_text, modelfile=modelfile)\n",
        "#print(processed_text[:350])\n",
        "  with open('/content/drive/MyDrive/kursovaya/for_training/my_text' + str(c) + '.txt', 'w', encoding='utf-8') as out:\n",
        "    out.write(processed_text)\n",
        "    c+=1\n",
        "    print(c)"
      ],
      "metadata": {
        "id": "p7EbQp3-taxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "id": "RE_QhjU-0Yys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim --upgrade"
      ],
      "metadata": {
        "id": "dVXp0Zz505G_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import gensim, logging\n",
        "\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "metadata": {
        "id": "vGja05LL0hNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = 'my_text.txt'\n",
        "data = gensim.models.word2vec.LineSentence(f)"
      ],
      "metadata": {
        "id": "qaSaajzY0mjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = gensim.models.Word2Vec(data, vector_size=500, window=3, min_count=2, sg=0)"
      ],
      "metadata": {
        "id": "y9uxRsXC0sBW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(model.wv.key_to_index))"
      ],
      "metadata": {
        "id": "jRYvHVpq1ULK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from os import cpu_count\n",
        "from gensim.models import Word2Vec\n",
        "import gensim\n",
        "import logging\n",
        "import time\n",
        "\n",
        "start = time.time()\n",
        "data = []\n",
        "c=0\n",
        "for c in range(614):\n",
        "    with open(os.path.join('/content/drive/MyDrive/kursovaya/for_training/my_text' + str(c) + '.txt')):\n",
        "        data.extend(gensim.models.word2vec.LineSentence('/content/drive/MyDrive/kursovaya/for_training/my_text' + str(c) + '.txt'))\n",
        "        c+=1\n",
        "        print(c)\n",
        "\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
        "w2v_model = Word2Vec(data, min_count=1, window=3, vector_size=400, negative=10, alpha=0.03, min_alpha=0.0007, sg=0, workers=cpu_count())\n",
        "w2v_model.save(\"word2vec.model\")\n",
        "\n",
        "\n",
        "\n",
        "print(w2v_model.wv.most_similar(positive='солнце_NOUN', topn=5))\n",
        "\n",
        "print(len(w2v_model.wv.key_to_index))\n",
        "\n",
        "print(time.time()-start)"
      ],
      "metadata": {
        "id": "Rx0PA0S19jJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "model_21 = gensim.models.KeyedVectors.load_word2vec_format('/content/drive/MyDrive/220/model.bin', binary = True)\n",
        "model_19 = gensim.models.KeyedVectors.load_word2vec_format('/content/drive/MyDrive/kursovaya/model.bin', binary = True)\n",
        "my_model = Word2Vec.load('word2vec.model')"
      ],
      "metadata": {
        "id": "f0L2tJR-XdvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word = 'каменный_ADJ'\n",
        "print(model_21.most_similar(positive=word, topn=5))\n",
        "print(model_19.most_similar(positive=word, topn=5))\n",
        "print(my_model.wv.most_similar(positive=word, topn=5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfBKS7Tmuy7i",
        "outputId": "9c8d964f-60e1-43c2-9ecf-6e0811b4a55c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('деревянный_ADJ', 0.789763867855072), ('кирпичный_ADJ', 0.6676967144012451), ('белокаменный_ADJ', 0.6330768465995789), ('гранитный_ADJ', 0.6321970224380493), ('бревенчатый_ADJ', 0.6212176084518433)]\n",
            "[('гранитный_ADJ', 0.6750349402427673), ('деревянный_ADJ', 0.6713505387306213), ('тесаный_ADJ', 0.6575525403022766), ('кирпичный_ADJ', 0.6524932980537415), ('чугунный_ADJ', 0.6057920455932617)]\n",
            "[('глиняный_ADJ', 0.6837567687034607), ('гранитный_ADJ', 0.675308346748352), ('земляной_ADJ', 0.6619945764541626), ('деревянный_ADJ', 0.6281141042709351), ('массивный_ADJ', 0.6235159635543823)]\n"
          ]
        }
      ]
    }
  ]
}